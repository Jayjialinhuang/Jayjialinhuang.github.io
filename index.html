<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jialin Huang</title>

    <meta name="author" content="Jialin Huang 黄佳琳">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Header: Name, Bio, Photo -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jialin Huang <span style=\"font-family: 'Noto Sans SC','PingFang SC','Microsoft YaHei',sans-serif;\">黄佳琳</span>
                </p>
                <p>
                  I am a fifth-year PhD student in Computer Science at <a href="https://www.gmu.edu/">George Mason University</a>, advised by <a href="https://cragl.cs.gmu.edu/">Prof. Yotam Gingold</a>. My research sits at the intersection of computer graphics and HCI, with an emphasis on accessible multimodal creative tools—systems that turn messy human input (hand motion, sketches, speech, and video) into controllable 3D content and sound.
                </p>
                <p>
                  I am especially interested in non-visual interaction for Blind and Visually Impaired (BVI) users: how to make geometry perceivable through sound, and how to make creative workflows more learnable for non-experts. Recent projects include ShapeSonic (sonifying fingertip interactions for virtual shape perception) and MoSound (generative sound design for motion graphics).
                </p>
                <p>
                  Before GMU, I earned a B.S. in Applied Mathematics from <a href="https://en.ustc.edu.cn/">the University of Science and Technology of China (USTC)</a>. I previously interned at <a href="https://www.adobe.com/">Adobe</a> Research (2024) with <a href="https://rubaiathabib.me/">Rubaiat Habib Kazi</a>, collaborating with <a href="https://pseeth.github.io/">Prem Seetharaman</a>, <a href="https://langlo.is/">Timothy Richard Langlois</a>, and <a href="https://www.liyiwei.org/">Li-Yi Wei</a>.
                </p>
                <p style="text-align:center">
                  <a href="data/Jialin_CV.pdf">CV</a> &nbsp;/&nbsp;
                  <!-- <a href="mailto:janbinco123@gmail.com">Email</a> &nbsp;/&nbsp; -->
                  <a href="https://scholar.google.com/citations?user=RQZpXBMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Janbinco">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/JialinHuang.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JialinHuang.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <!-- Research Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>

          <!-- Publications -->
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr bgcolor="#FFE7C2">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <img src='images/mosound.png' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">MoSound: An Interactive Tool for Generative Sound Design in Motion Graphics</span>
                <br>
                <strong>Jialin Huang</strong>,
                <a href="https://pseeth.github.io/">Prem Seetharaman</a>,
                <a href="https://langlo.is/">Timothy Richard Langlois</a>,
                <a href="https://www.liyiwei.org/">Li-Yi Wei</a>,
                <a href="https://rubaiathabib.me/">Rubaiat Habib Kazi</a>,
                <a href="https://cragl.cs.gmu.edu/">Yotam Gingold</a>
                <br>
                <em>CHI</em>, 2026
                <br>
                <a href="data/mosound.pdf">paper</a>
                /
                <a href="https://cragl.cs.gmu.edu/mosound/">project page</a>
                <p></p>
                <p>
                  MoSound is an interactive system for adding sound effects to motion graphics videos. It detects key visual events, suggests short sound descriptions, and lets users map motion features (e.g., position and velocity) to audio properties (e.g., stereo panning and volume) to guide generative sound synthesis.
                </p>
              </td>
            </tr>



            <tr bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <img src='images/shapesonic.jpg' width=100%>
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                  <span class="papertitle">ShapeSonic: Sonifying Fingertip Interactions for Non-Visual Virtual Shape Perception</span>
                <br>
                <strong>Jialin Huang</strong>,
                <a href="https://www.cs.uchicago.edu/people/rana-hanocka/">Rana Hanocka</a>,
                <a href="https://research.adobe.com/person/alexa-siu/">Alexa Siu</a>,
                <a href="https://cragl.cs.gmu.edu/">Yotam Gingold</a>
                <br>
                <em>SIGGRAPH Asia</em>, 2023
                <br>
                <a href="https://cragl.cs.gmu.edu/shapesonic/">paper</a>
                /
                <a href="https://cragl.cs.gmu.edu/shapesonic/">project page</a>
                <p></p>
                <p>
                  ShapeSonic is a system designed to convey vivid 3D shape perception using purely audio feedback or sonification. ShapeSonic tracks users' fingertips in 3D and provides real-time sound feedback, based on a mass-produced, commodity hardware platform (Oculus Quest). In a study with 15 sighted and 6 BVI users, we demonstrate the value of ShapeSonic in shape landmark localization and recognition.
                </p>
              </td>
            </tr>

</tbody></table>

          <!-- Education Section -->
          





          <!-- Footer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
